from flask import Flask, render_template, request
from flask import Markup, jsonify
import os

import uuid
from datetime import datetime

import random


import cv2
import torch
from numpy import random

from models.experimental import attempt_load
from utils.datasets import LoadStreams, LoadImages
from utils.general import check_img_size, check_requirements, check_imshow, non_max_suppression, apply_classifier, \
    scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path
from utils.plots import plot_one_box
from utils.torch_utils import select_device, load_classifier, time_synchronized


# Khởi tạo Flask
app = Flask(__name__)
app.config['UPLOAD_FOLDER'] = "storages/images"

# Load model
weights = 'yolov5x.pt'
set_logging()
device = select_device('')
half = device.type != 'cpu'
imgsz = 640

# Load model
model = attempt_load(weights, map_location=device)  # load FP32 model
stride = int(model.stride.max())  # model stride
imgsz = check_img_size(imgsz, s=stride)  # check img_size
if half:
    model.half()  # to FP16


# Hàm xử lý request
@app.route("/", methods=['GET', 'POST'])
def home_page():
    # Nếu là POST (gửi file)
    if request.method == "POST":
         try:
            # Lấy file gửi lên
            image = request.files['file']
            if image:
                # Lưu file
                print(image.filename)
                print(app.config['UPLOAD_FOLDER'])
                now = datetime.now()
                timestamp = now.strftime('%Y%m%dT%H%M%S') + ('%02d' % (now.microsecond / 10000))
                filename = timestamp + '_' + str(uuid.uuid4().hex) + '_' + image.filename
                source = os.path.join(app.config['UPLOAD_FOLDER'], filename)
                print("Save = ", source)
                image.save(source)

                # source = "data/images/sample4.jpg"
                dataset = LoadImages(source, img_size=imgsz, stride=stride)

                # remove file
                #os.remove(source)

                # Get names and colors
                names = model.module.names if hasattr(model, 'module') else model.names
                colors = [[random.randint(0, 255) for _ in range(3)] for _ in names]

                # Run inference
                if device.type != 'cpu':
                    model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))  # run once

                conf_thres = 0.25
                iou_thres = 0.25

                rs = []

                for path, img, im0s, vid_cap in dataset:
                    img = torch.from_numpy(img).to(device)
                    img = img.half() if half else img.float()  # uint8 to fp16/32
                    img /= 255.0  # 0 - 255 to 0.0 - 1.0
                    if img.ndimension() == 3:
                        img = img.unsqueeze(0)

                    # Inference
                    pred = model(img, augment=False)[0]

                    # Apply NMS
                    pred = non_max_suppression(pred, conf_thres, iou_thres, classes=None, agnostic=False)

                    # Process detections
                    for i, det in enumerate(pred):  # detections per image
                        p, s, im0, frame = path, '', im0s, getattr(dataset, 'frame', 0)
                        save_path = source
                        if len(det):
                            # Rescale boxes from img_size to im0 size
                            det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()
                            gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]
                            # Write results
                            for *xyxy, conf, cls in reversed(det):
                                xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh
                                data = (int(cls), float(conf), *xywh, names[int(cls)])
                                rs.append(data)

                # Trả về kết quả
                return jsonify({'status': 200, 'data': rs, 'message': 'success'})

            else:
                # Nếu không có file thì yêu cầu tải file
                return jsonify({'status': 500, 'message': 'an error occus'})

         except Exception as ex:
            print(ex)
            # Nếu lỗi thì thông báo
            return jsonify({'status': 400, 'message': 'an error occus'})

    else:
        # Nếu là GET thì hiển thị giao diện upload
        return render_template('index.html')


if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8000, debug=False, threaded=True)
